{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d0d80981-6ee0-47de-bb9e-dabc4279b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "91dd6725-b23e-44dc-bef1-693f5954c304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"news.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cc45df7e-fac6-4412-ac2c-1e8a2274e4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6335, 4)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9306c0d4-2400-4dea-9d17-914b90e20c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35b618b7-65ae-4ea8-9312-85859059323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99e176f2-85b0-4353-925c-f852140d7679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ca954e8-c146-47de-8c92-3324b2d1b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.countplot(x='label', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc8cca75-e040-486a-ab22-83aa9a07a67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                       You Can Smell Hillary’s Fear   \n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        Kerry to go to Paris in gesture of sympathy   \n",
       "3  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6c615818-9d94-41e2-aad8-6cb6b857a621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                 0\n",
       "text                  0\n",
       "label                 0\n",
       "title_tokenize        0\n",
       "text_tokenize         0\n",
       "title_tokenize_str    0\n",
       "text_tokenize_str     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce626b7e-8f85-43e4-b36c-b4647932e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7f213c8-42f4-46b5-b795-5dd6c25931c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f670f06-1234-4c14-b82a-779add7df3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def count_words(text):\n",
    "#     return len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "023496b3-38de-4f67-a839-681a894fe650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['word_count_title'] = (df['title']).apply(count_words)\n",
    "# df['word_count_text'] = (df['text']).apply(count_words)\n",
    "# df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c29b41d-4a40-4b74-b6b0-6d16de442f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_value_title = df['word_count_title'].max()\n",
    "# max_value_text = df['word_count_text'].max()\n",
    "# print(max_value_title)\n",
    "# print(max_value_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa361a3e-4f1c-4d8b-acdf-7f6ca2cd46e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "  # Lower case\n",
    "  text = text.lower()\n",
    "  #print(\"lower text\", text)\n",
    "  # Removing punctuation\n",
    "  text = re.sub(r'[^\\w\\s]','',text)\n",
    "  #print(\"lower text\", text)\n",
    "  # Removing numbers\n",
    "  text = re.sub(r'\\d+', '', text)\n",
    "  #print(\"lower text\", text)\n",
    "  # Removing whitespace\n",
    "  text = text.strip()\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63b8b6f0-867b-456b-b710-294067923078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6335"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6dfdacda-964c-4f84-a198-86c8713fc5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_tokenize\"]=df[\"title\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3846b62e-976a-402b-a6aa-792f72064d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_tokenize\"]=df[\"text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0566714-9e88-4639-87d1-93244b7f50dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>title_tokenize</th>\n",
       "      <th>text_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>you can smell hillarys fear</td>\n",
       "      <td>daniel greenfield a shillman journalism fellow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>watch the exact moment paul ryan committed pol...</td>\n",
       "      <td>google pinterest digg linkedin reddit stumbleu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>kerry to go to paris in gesture of sympathy</td>\n",
       "      <td>us secretary of state john f kerry said monday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>bernie supporters on twitter erupt in anger ag...</td>\n",
       "      <td>kaydee king kaydeeking november   the lesson f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>the battle of new york why this primary matters</td>\n",
       "      <td>its primary day in new york and frontrunners h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                       You Can Smell Hillary’s Fear   \n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        Kerry to go to Paris in gesture of sympathy   \n",
       "3  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \\\n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE   \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE   \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL   \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE   \n",
       "4  It's primary day in New York and front-runners...  REAL   \n",
       "\n",
       "                                      title_tokenize  \\\n",
       "0                        you can smell hillarys fear   \n",
       "1  watch the exact moment paul ryan committed pol...   \n",
       "2        kerry to go to paris in gesture of sympathy   \n",
       "3  bernie supporters on twitter erupt in anger ag...   \n",
       "4    the battle of new york why this primary matters   \n",
       "\n",
       "                                       text_tokenize  \n",
       "0  daniel greenfield a shillman journalism fellow...  \n",
       "1  google pinterest digg linkedin reddit stumbleu...  \n",
       "2  us secretary of state john f kerry said monday...  \n",
       "3  kaydee king kaydeeking november   the lesson f...  \n",
       "4  its primary day in new york and frontrunners h...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b70f2aa-d7b6-46ad-9174-d2c7239c5f6e",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7eddadfa-a1b3-4ca7-8ff5-b879e3f1682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dfb00397-1c6f-4068-b769-c9b4c96562c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/rajat/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/rajat/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/rajat/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5dd7d9ed-873a-4b9d-a571-6690894c5d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82f7d680-b016-4085-83a0-deb27301410d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words 198\n"
     ]
    }
   ],
   "source": [
    "print('Number of stop words', len(stop_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "51d3041a-d7e9-409e-969a-7049b5c8d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "  # Lower case\n",
    "  text = text.lower()\n",
    "  #print(\"lower text\", text)\n",
    "  # Removing punctuation\n",
    "  text = re.sub(r'[^\\w\\s]','',text)\n",
    "  #print(\"lower text\", text)\n",
    "  # Removing numbers\n",
    "  text = re.sub(r'\\d+', '', text)\n",
    "  #print(\"lower text\", text)\n",
    "  # Removing whitespace\n",
    "  text = text.strip()\n",
    "  # Sentence Tokenization\n",
    "  sentences = nltk.sent_tokenize(text)\n",
    "  # Word Tokenization and stop words\n",
    "  stop_word = nltk.corpus.stopwords.words('english')\n",
    "  words = [word for sentence in sentences for word in nltk.word_tokenize(sentence) if word not in stop_word]\n",
    "  return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aca32f90-b9d5-4308-938a-88b8dc905cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_tokenize\"] = df[\"title_tokenize\"].apply(tokenize)\n",
    "df[\"text_tokenize\"] = df[\"text_tokenize\"].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a944b06a-d4f6-483f-ae6c-3a02f5f017d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>title_tokenize</th>\n",
       "      <th>text_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>[smell, hillarys, fear]</td>\n",
       "      <td>[daniel, greenfield, shillman, journalism, fel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>[watch, exact, moment, paul, ryan, committed, ...</td>\n",
       "      <td>[google, pinterest, digg, linkedin, reddit, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[kerry, go, paris, gesture, sympathy]</td>\n",
       "      <td>[us, secretary, state, john, f, kerry, said, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>[bernie, supporters, twitter, erupt, anger, dn...</td>\n",
       "      <td>[kaydee, king, kaydeeking, november, lesson, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[battle, new, york, primary, matters]</td>\n",
       "      <td>[primary, day, new, york, frontrunners, hillar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                       You Can Smell Hillary’s Fear   \n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        Kerry to go to Paris in gesture of sympathy   \n",
       "3  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \\\n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE   \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE   \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL   \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE   \n",
       "4  It's primary day in New York and front-runners...  REAL   \n",
       "\n",
       "                                      title_tokenize  \\\n",
       "0                            [smell, hillarys, fear]   \n",
       "1  [watch, exact, moment, paul, ryan, committed, ...   \n",
       "2              [kerry, go, paris, gesture, sympathy]   \n",
       "3  [bernie, supporters, twitter, erupt, anger, dn...   \n",
       "4              [battle, new, york, primary, matters]   \n",
       "\n",
       "                                       text_tokenize  \n",
       "0  [daniel, greenfield, shillman, journalism, fel...  \n",
       "1  [google, pinterest, digg, linkedin, reddit, st...  \n",
       "2  [us, secretary, state, john, f, kerry, said, m...  \n",
       "3  [kaydee, king, kaydeeking, november, lesson, t...  \n",
       "4  [primary, day, new, york, frontrunners, hillar...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed427ce9-bd38-45d5-b28c-43dc7fc3b223",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d719852-7afc-4914-a0ce-4968110e2483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem import PorterStemmer\n",
    "\n",
    "# stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "739a6586-2436-460e-8851-4b1700f96b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Each row in 'title_tokenize' is a list of tokens\n",
    "# df[\"title_token_str\"] = df[\"title_tokenize\"].apply(lambda tokens: ' '.join(tokens))\n",
    "# df[\"title_tokenize\"] = [stemmer.stem(word) for word in df[\"title_token_str\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93384dd6-180c-4d3c-8f41-a4a5f00ff076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Each row in 'title_tokenize' is a list of tokens\n",
    "# df[\"text_token_str\"] = df[\"text_tokenize\"].apply(lambda tokens: ' '.join(tokens))\n",
    "# df[\"text_tokenize\"] = [stemmer.stem(word) for word in df[\"text_token_str\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "46b60ba4-1064-48d1-809a-1b2d6c527790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041ae7ca-9b56-4300-a752-e1ba57b69a5e",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "59b19523-7321-4cd5-8754-46215de08af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c409b195-4f54-4a10-adec-2a5e79c74639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "65b1f954-411c-4c66-9c99-a6e1d9641554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem import WordNetLemmatizer\n",
    "# from nltk.corpus import wordnet\n",
    "# from nltk import word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "855b2788-595a-4854-8406-944a505605d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_wordnet_pos(tag):\n",
    "#   if tag.startswith('J'):\n",
    "#     return wordnet.ADJ\n",
    "#   elif tag.startswith('V'):\n",
    "#     return wordnet.VERB\n",
    "#   elif tag.startswith('N'):\n",
    "#     return wordnet.NOUN\n",
    "#   elif tag.startswith('R'):\n",
    "#     return wordnet.ADV\n",
    "#   else:\n",
    "#     return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb5c64e0-adfe-4b5a-bfe4-dbfee842643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lemmatize_passage(text):\n",
    "#   words = word_tokenize(text)\n",
    "#   pos_tags = pos_tag(words)\n",
    "#   lemmatizer = WordNetLemmatizer()\n",
    "#   lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "#   lemmatized_sentence = ' '.join(lemmatized_words)\n",
    "#   return lemmatized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "25b22e26-5061-4ee2-943a-d568202cd6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "58d32d5f-7cd9-4b53-b9b5-93346437d9f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # df[\"title_token_str\"] = df[\"title_tokenize\"].apply(lambda tokens: ' '.join(tokens))\n",
    "# df[\"title_tokenize\"] = df[\"title_tokenize\"].apply(lemmatize_passage)\n",
    "# df[\"text_tokenize\"] = df[\"text_tokenize\"].apply(lemmatize_passage)\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635cc583-708e-4c9b-badf-4e318c52f4c6",
   "metadata": {},
   "source": [
    "# Label Encodeing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "31419b84-bd60-4d69-833b-47ccb0f0cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize encoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ac5d6715-e0f9-4ea7-aa2c-0566b011eb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>title_tokenize</th>\n",
       "      <th>text_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>0</td>\n",
       "      <td>[smell, hillarys, fear]</td>\n",
       "      <td>[daniel, greenfield, shillman, journalism, fel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>0</td>\n",
       "      <td>[watch, exact, moment, paul, ryan, committed, ...</td>\n",
       "      <td>[google, pinterest, digg, linkedin, reddit, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>1</td>\n",
       "      <td>[kerry, go, paris, gesture, sympathy]</td>\n",
       "      <td>[us, secretary, state, john, f, kerry, said, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>0</td>\n",
       "      <td>[bernie, supporters, twitter, erupt, anger, dn...</td>\n",
       "      <td>[kaydee, king, kaydeeking, november, lesson, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>1</td>\n",
       "      <td>[battle, new, york, primary, matters]</td>\n",
       "      <td>[primary, day, new, york, frontrunners, hillar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                       You Can Smell Hillary’s Fear   \n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        Kerry to go to Paris in gesture of sympathy   \n",
       "3  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...      0   \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...      0   \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...      1   \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...      0   \n",
       "4  It's primary day in New York and front-runners...      1   \n",
       "\n",
       "                                      title_tokenize  \\\n",
       "0                            [smell, hillarys, fear]   \n",
       "1  [watch, exact, moment, paul, ryan, committed, ...   \n",
       "2              [kerry, go, paris, gesture, sympathy]   \n",
       "3  [bernie, supporters, twitter, erupt, anger, dn...   \n",
       "4              [battle, new, york, primary, matters]   \n",
       "\n",
       "                                       text_tokenize  \n",
       "0  [daniel, greenfield, shillman, journalism, fel...  \n",
       "1  [google, pinterest, digg, linkedin, reddit, st...  \n",
       "2  [us, secretary, state, john, f, kerry, said, m...  \n",
       "3  [kaydee, king, kaydeeking, november, lesson, t...  \n",
       "4  [primary, day, new, york, frontrunners, hillar...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and transition\n",
    "df[\"label\"] = le.fit_transform(df[\"label\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "596568ca-731a-4574-8437-4ce78a8349a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>title_tokenize</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>title_tokenize_str</th>\n",
       "      <th>text_tokenize_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>0</td>\n",
       "      <td>[smell, hillarys, fear]</td>\n",
       "      <td>[daniel, greenfield, shillman, journalism, fel...</td>\n",
       "      <td>smell hillarys fear</td>\n",
       "      <td>daniel greenfield shillman journalism fellow f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>0</td>\n",
       "      <td>[watch, exact, moment, paul, ryan, committed, ...</td>\n",
       "      <td>[google, pinterest, digg, linkedin, reddit, st...</td>\n",
       "      <td>watch exact moment paul ryan committed politic...</td>\n",
       "      <td>google pinterest digg linkedin reddit stumbleu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>1</td>\n",
       "      <td>[kerry, go, paris, gesture, sympathy]</td>\n",
       "      <td>[us, secretary, state, john, f, kerry, said, m...</td>\n",
       "      <td>kerry go paris gesture sympathy</td>\n",
       "      <td>us secretary state john f kerry said monday st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>0</td>\n",
       "      <td>[bernie, supporters, twitter, erupt, anger, dn...</td>\n",
       "      <td>[kaydee, king, kaydeeking, november, lesson, t...</td>\n",
       "      <td>bernie supporters twitter erupt anger dnc trie...</td>\n",
       "      <td>kaydee king kaydeeking november lesson tonight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>1</td>\n",
       "      <td>[battle, new, york, primary, matters]</td>\n",
       "      <td>[primary, day, new, york, frontrunners, hillar...</td>\n",
       "      <td>battle new york primary matters</td>\n",
       "      <td>primary day new york frontrunners hillary clin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                       You Can Smell Hillary’s Fear   \n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        Kerry to go to Paris in gesture of sympathy   \n",
       "3  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...      0   \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...      0   \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...      1   \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...      0   \n",
       "4  It's primary day in New York and front-runners...      1   \n",
       "\n",
       "                                      title_tokenize  \\\n",
       "0                            [smell, hillarys, fear]   \n",
       "1  [watch, exact, moment, paul, ryan, committed, ...   \n",
       "2              [kerry, go, paris, gesture, sympathy]   \n",
       "3  [bernie, supporters, twitter, erupt, anger, dn...   \n",
       "4              [battle, new, york, primary, matters]   \n",
       "\n",
       "                                       text_tokenize  \\\n",
       "0  [daniel, greenfield, shillman, journalism, fel...   \n",
       "1  [google, pinterest, digg, linkedin, reddit, st...   \n",
       "2  [us, secretary, state, john, f, kerry, said, m...   \n",
       "3  [kaydee, king, kaydeeking, november, lesson, t...   \n",
       "4  [primary, day, new, york, frontrunners, hillar...   \n",
       "\n",
       "                                  title_tokenize_str  \\\n",
       "0                                smell hillarys fear   \n",
       "1  watch exact moment paul ryan committed politic...   \n",
       "2                    kerry go paris gesture sympathy   \n",
       "3  bernie supporters twitter erupt anger dnc trie...   \n",
       "4                    battle new york primary matters   \n",
       "\n",
       "                                   text_tokenize_str  \n",
       "0  daniel greenfield shillman journalism fellow f...  \n",
       "1  google pinterest digg linkedin reddit stumbleu...  \n",
       "2  us secretary state john f kerry said monday st...  \n",
       "3  kaydee king kaydeeking november lesson tonight...  \n",
       "4  primary day new york frontrunners hillary clin...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title_tokenize_str'] = df['title_tokenize'].apply(lambda tokens: ' '.join(tokens))\n",
    "df['text_tokenize_str'] = df['text_tokenize'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bdff30dd-6cc3-4305-be35-2bbb0068a683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6335 entries, 0 to 6334\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   title               6335 non-null   object\n",
      " 1   text                6335 non-null   object\n",
      " 2   label               6335 non-null   int64 \n",
      " 3   title_tokenize      6335 non-null   object\n",
      " 4   text_tokenize       6335 non-null   object\n",
      " 5   title_tokenize_str  6335 non-null   object\n",
      " 6   text_tokenize_str   6335 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 346.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7c70fb78-ce60-4e5b-a94b-8f5a8a996a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"tokenized1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "312a955c-0ef8-4a1c-bea7-098c5470bb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6335 entries, 0 to 6334\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   title               6335 non-null   object\n",
      " 1   text                6335 non-null   object\n",
      " 2   label               6335 non-null   int64 \n",
      " 3   title_tokenize      6335 non-null   object\n",
      " 4   text_tokenize       6335 non-null   object\n",
      " 5   title_tokenize_str  6335 non-null   object\n",
      " 6   text_tokenize_str   6335 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 346.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f847a47-cd94-49ad-b4a5-47ebf3548798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "61488458-2f2d-4607-9785-7a2649faa9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop([\"title\",\"text\",\"word_count_title\",\"word_count_text\",\"title_token_str\",\"text_token_str\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f4be0e30-e268-474b-ad17-50ca425bf85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "50df5602-eeb9-42a8-8d9e-c5cb2e40ab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8c424c13-3b46-4d10-b0f9-4b999f67028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Separate features and target\n",
    "# X = df.drop(['label',\"title_tokenize\",\"text_tokenize\"], axis=1)\n",
    "# y = df['label']\n",
    "\n",
    "# # 2. Split into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f527896c-a285-4608-a5e2-6da77dbc12c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3. Initialize and train Logistic Regression model\n",
    "# model = LogisticRegression(max_iter=1000)\n",
    "# model.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
